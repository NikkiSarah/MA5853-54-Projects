{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "# Probably more functions than you'll need...\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import matplotlib\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# Install new libraries\n",
    "#%pip install pyspellchecker\n",
    "#%pip install TextBlob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrame from CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define File Path\n",
    "\n",
    "data_path = 'pre_processed_vodafone_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed dataset into DataFrame\n",
    "preprocessed_vodafone_reviews = pd.read_csv(data_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentences', 'noun_phrases', 'lemmatised_sentences', 'bi_grams', 'tri_grams', 'words', 'nouns']\n"
     ]
    }
   ],
   "source": [
    "# Identify which columns are lists\n",
    "\n",
    "columns = list(preprocessed_vodafone_reviews.columns)\n",
    "\n",
    "# create empty list to contain a list of columns that are lists...  listslistslistslists...lists\n",
    "list_columns = []\n",
    "\n",
    "\n",
    "for column in columns:\n",
    "    first_row_value = str(preprocessed_vodafone_reviews[column].iloc[0])\n",
    "    first_character = first_row_value[0]\n",
    "    last_character = first_row_value[len(first_row_value)-1]\n",
    "    # A column /probably/ contains lists if values starte with a [ and end with a ]\n",
    "    if first_character == \"[\" and last_character == \"]\":\n",
    "        list_columns = list_columns + [column]\n",
    "        \n",
    "print(list_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review_sentiment</th>\n",
       "      <th>sentences</th>\n",
       "      <th>lemmatised_title</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>lemmatised_sentences</th>\n",
       "      <th>bi_grams</th>\n",
       "      <th>tri_grams</th>\n",
       "      <th>words</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vodafone almost ruined my life - stolen identi...</td>\n",
       "      <td>my email and password were part of a company d...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-31 01:03:34+00:00</td>\n",
       "      <td>-0.9390</td>\n",
       "      <td>[(vodafone almost ruined my life - stolen iden...</td>\n",
       "      <td>vodafone almost ruin life steal identity security</td>\n",
       "      <td>[(company database leak, -0.34, 1), (vodafone ...</td>\n",
       "      <td>[(vodafone almost ruin life steal identity sec...</td>\n",
       "      <td>[(ruin life, -0.5584, 1), (life steal, -0.5584...</td>\n",
       "      <td>[(vodafone almost ruin, -0.5584, 1), (ruin lif...</td>\n",
       "      <td>[(vodafone, -0.5584, 1), (almost, -0.5584, 1),...</td>\n",
       "      <td>[(vodafone, -0.5584, 1), (life, -0.5584, 1), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>misguided sale</td>\n",
       "      <td>misguided salecouple of days ago, i was told t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-29 08:59:16+00:00</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>[(misguided sale, 0.0, 1), (misguided salecoup...</td>\n",
       "      <td>misguide sale</td>\n",
       "      <td>[(trade in value, 0.34, 1), (old phone, 0.34, ...</td>\n",
       "      <td>[(misguide, 0.0, 1), (misguided salecouple day...</td>\n",
       "      <td>[(misguide sale, 0.0, 1), (misguided salecoupl...</td>\n",
       "      <td>[(misguided salecouple day, 0.34, 1), (trade i...</td>\n",
       "      <td>[(misguide, 0.0, 1), (misguided, 0.34, 1), (sa...</td>\n",
       "      <td>[(misguide, 0.0, 1), (salecouple, 0.34, 1), (d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>worst network</td>\n",
       "      <td>worst network for data in australia. i used vo...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-28 12:16:46+00:00</td>\n",
       "      <td>-0.6858</td>\n",
       "      <td>[(worst network, -0.6249, 1), (worst network f...</td>\n",
       "      <td>bad network</td>\n",
       "      <td>[(mobile phone, -0.7227, 1), (i need data, -0....</td>\n",
       "      <td>[(bad network, -0.6249, 1), (bad network data ...</td>\n",
       "      <td>[(bad network, -0.6249, 1), (bad network, -0.6...</td>\n",
       "      <td>[(network for data, -0.6249, 1), (i use vodafo...</td>\n",
       "      <td>[(bad, -0.6249, 1), (network, -0.6249, 1), (ba...</td>\n",
       "      <td>[(network, -0.6249, 1), (network, -0.6249, 1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>insurance contract with them is bullshit</td>\n",
       "      <td>they charged me for over a year a plan with in...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-27 06:21:26+00:00</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>[(insurance contract with them is bullshit, -0...</td>\n",
       "      <td>insurance contract with them bullshit</td>\n",
       "      <td>[(insurance contract, -0.5859, 1), (free phone...</td>\n",
       "      <td>[(insurance contract bullshit, -0.5859, 1), (c...</td>\n",
       "      <td>[(insurance contract, -0.5859, 1), (year plan,...</td>\n",
       "      <td>[(plan with insurance, 0.3612, 1), (month free...</td>\n",
       "      <td>[(insurance, -0.5859, 1), (contract, -0.5859, ...</td>\n",
       "      <td>[(insurance, -0.5859, 1), (contract, -0.5859, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>record all your phonecalls with them when you ...</td>\n",
       "      <td>my parents and i have been with vodafone for a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-27 04:18:19+00:00</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>[(record all your phonecalls with them when yo...</td>\n",
       "      <td>record all your phonecalls with them when you ...</td>\n",
       "      <td>[(decent coverage, 0.0, 1), (cheap price, 0.0,...</td>\n",
       "      <td>[(record phonecalls issue, 0.0, 1), (parent vo...</td>\n",
       "      <td>[(decent coverage, 0.0, 1), (cheap price, 0.0,...</td>\n",
       "      <td>[(thats strictly due, 0.0, 1), (company with d...</td>\n",
       "      <td>[(record, 0.0, 1), (phonecalls, 0.0, 1), (issu...</td>\n",
       "      <td>[(record, 0.0, 1), (issue, 0.0, 1), (parent, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                              title  \\\n",
       "0          1  vodafone almost ruined my life - stolen identi...   \n",
       "1          2                                     misguided sale   \n",
       "2          3                                      worst network   \n",
       "3          4           insurance contract with them is bullshit   \n",
       "4          5  record all your phonecalls with them when you ...   \n",
       "\n",
       "                                              review  score  \\\n",
       "0  my email and password were part of a company d...      1   \n",
       "1  misguided salecouple of days ago, i was told t...      1   \n",
       "2  worst network for data in australia. i used vo...      1   \n",
       "3  they charged me for over a year a plan with in...      1   \n",
       "4  my parents and i have been with vodafone for a...      1   \n",
       "\n",
       "                   timestamp  review_sentiment  \\\n",
       "0  2021-01-31 01:03:34+00:00           -0.9390   \n",
       "1  2021-01-29 08:59:16+00:00            0.8555   \n",
       "2  2021-01-28 12:16:46+00:00           -0.6858   \n",
       "3  2021-01-27 06:21:26+00:00            0.3612   \n",
       "4  2021-01-27 04:18:19+00:00            0.4926   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [(vodafone almost ruined my life - stolen iden...   \n",
       "1  [(misguided sale, 0.0, 1), (misguided salecoup...   \n",
       "2  [(worst network, -0.6249, 1), (worst network f...   \n",
       "3  [(insurance contract with them is bullshit, -0...   \n",
       "4  [(record all your phonecalls with them when yo...   \n",
       "\n",
       "                                    lemmatised_title  \\\n",
       "0  vodafone almost ruin life steal identity security   \n",
       "1                                      misguide sale   \n",
       "2                                        bad network   \n",
       "3              insurance contract with them bullshit   \n",
       "4  record all your phonecalls with them when you ...   \n",
       "\n",
       "                                        noun_phrases  \\\n",
       "0  [(company database leak, -0.34, 1), (vodafone ...   \n",
       "1  [(trade in value, 0.34, 1), (old phone, 0.34, ...   \n",
       "2  [(mobile phone, -0.7227, 1), (i need data, -0....   \n",
       "3  [(insurance contract, -0.5859, 1), (free phone...   \n",
       "4  [(decent coverage, 0.0, 1), (cheap price, 0.0,...   \n",
       "\n",
       "                                lemmatised_sentences  \\\n",
       "0  [(vodafone almost ruin life steal identity sec...   \n",
       "1  [(misguide, 0.0, 1), (misguided salecouple day...   \n",
       "2  [(bad network, -0.6249, 1), (bad network data ...   \n",
       "3  [(insurance contract bullshit, -0.5859, 1), (c...   \n",
       "4  [(record phonecalls issue, 0.0, 1), (parent vo...   \n",
       "\n",
       "                                            bi_grams  \\\n",
       "0  [(ruin life, -0.5584, 1), (life steal, -0.5584...   \n",
       "1  [(misguide sale, 0.0, 1), (misguided salecoupl...   \n",
       "2  [(bad network, -0.6249, 1), (bad network, -0.6...   \n",
       "3  [(insurance contract, -0.5859, 1), (year plan,...   \n",
       "4  [(decent coverage, 0.0, 1), (cheap price, 0.0,...   \n",
       "\n",
       "                                           tri_grams  \\\n",
       "0  [(vodafone almost ruin, -0.5584, 1), (ruin lif...   \n",
       "1  [(misguided salecouple day, 0.34, 1), (trade i...   \n",
       "2  [(network for data, -0.6249, 1), (i use vodafo...   \n",
       "3  [(plan with insurance, 0.3612, 1), (month free...   \n",
       "4  [(thats strictly due, 0.0, 1), (company with d...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [(vodafone, -0.5584, 1), (almost, -0.5584, 1),...   \n",
       "1  [(misguide, 0.0, 1), (misguided, 0.34, 1), (sa...   \n",
       "2  [(bad, -0.6249, 1), (network, -0.6249, 1), (ba...   \n",
       "3  [(insurance, -0.5859, 1), (contract, -0.5859, ...   \n",
       "4  [(record, 0.0, 1), (phonecalls, 0.0, 1), (issu...   \n",
       "\n",
       "                                               nouns  \n",
       "0  [(vodafone, -0.5584, 1), (life, -0.5584, 1), (...  \n",
       "1  [(misguide, 0.0, 1), (salecouple, 0.34, 1), (d...  \n",
       "2  [(network, -0.6249, 1), (network, -0.6249, 1),...  \n",
       "3  [(insurance, -0.5859, 1), (contract, -0.5859, ...  \n",
       "4  [(record, 0.0, 1), (issue, 0.0, 1), (parent, 0...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lists will initially be expressed as strings when imported form CSV\n",
    "# We will use AST to convert these string columns back to list\n",
    "# This function could probably be better implemented without a for loop\n",
    "# but works for now...\n",
    "\n",
    "# List encode columns contain lists of tuples in the format:\n",
    "# (\"feature value\", \"Sentiment of originating sentence\", \"Review Promoter score\")\n",
    "\n",
    "# Abstract syntax tree is used to recreate the lists of tuples stored in the pre-processed data\n",
    "for i in range(len(preprocessed_vodafone_reviews)):\n",
    "    for column in list_columns:\n",
    "        preprocessed_vodafone_reviews[column].iloc[i] = list(ast.literal_eval(preprocessed_vodafone_reviews[column].iloc[i]))\n",
    "\n",
    "    \n",
    "preprocessed_vodafone_reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessor Functions (And other functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>promoter_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vodafone</td>\n",
       "      <td>-0.5584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>almost</td>\n",
       "      <td>-0.5584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ruin</td>\n",
       "      <td>-0.5584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>life</td>\n",
       "      <td>-0.5584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>steal</td>\n",
       "      <td>-0.5584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       term  sentiment promoter_score\n",
       "0  vodafone    -0.5584              1\n",
       "1    almost    -0.5584              1\n",
       "2      ruin    -0.5584              1\n",
       "3      life    -0.5584              1\n",
       "4     steal    -0.5584              1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a dataframe containing all occurances of a featiure value, \n",
    "# Along with the sentiment of the sentence in which they were found, \n",
    "# and the associated review score\n",
    "\n",
    "# Pass the observation dataframe, and the column to extract\n",
    "def term_df_with_scores(df, column):\n",
    "    term_frame = pd.DataFrame(columns = [\"term\",\"sentiment\",\"promoter_score\"])\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        row = df[column].iloc[i]\n",
    "        row_frame = pd.DataFrame.from_records(row, columns=['term','sentiment','promoter_score'])\n",
    "        term_frame = term_frame.append(row_frame)\n",
    "            \n",
    "    return term_frame\n",
    "\n",
    "\n",
    "term_df_with_scores(preprocessed_vodafone_reviews, 'words').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>sentiment_correlation</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old phone</td>\n",
       "      <td>0.130361</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new phone i</td>\n",
       "      <td>0.532814</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mobile phone</td>\n",
       "      <td>0.352996</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home wifi</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sure i</td>\n",
       "      <td>0.435640</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term  sentiment_correlation count\n",
       "0     old phone               0.130361    14\n",
       "0   new phone i               0.532814     4\n",
       "0  mobile phone               0.352996    45\n",
       "0     home wifi               1.000000     2\n",
       "0        sure i               0.435640    11"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a function to return the pearson correlation between score and sentiment \n",
    "# for Features encoded as leists of tuples\n",
    "\n",
    "# Pass the observation dataframe and feature column to process\n",
    "def get_corr(df, column):\n",
    "    term_frame = term_df_with_scores(df, column)\n",
    "    term_frame[[\"sentiment\", \"promoter_score\"]] = term_frame[[\"sentiment\", \"promoter_score\"]].apply(pd.to_numeric)\n",
    "    result_frame = pd.DataFrame(columns = [\"term\",\"sentiment_correlation\",\"count\"])\n",
    "    unique_terms = term_frame.term.unique()\n",
    "    \n",
    "    for term in unique_terms:\n",
    "        temp_frame = term_frame[term_frame.term==term]\n",
    "        correlation = temp_frame[\"sentiment\"].corr(temp_frame[\"promoter_score\"])\n",
    "        count = len(temp_frame)\n",
    "        if not np.isnan(correlation):\n",
    "            result_frame = result_frame.append(pd.DataFrame([[term, correlation, count]], columns = [\"term\",\"sentiment_correlation\",\"count\"]))\n",
    "    return result_frame\n",
    "\n",
    "get_corr(preprocessed_vodafone_reviews, 'noun_phrases').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>reviews_containing_term</th>\n",
       "      <th>percentage</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>customer service</td>\n",
       "      <td>368</td>\n",
       "      <td>19.337888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>time i</td>\n",
       "      <td>73</td>\n",
       "      <td>3.836048</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>new phone</td>\n",
       "      <td>68</td>\n",
       "      <td>3.573305</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>network coverage</td>\n",
       "      <td>48</td>\n",
       "      <td>2.522333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>loyal customer</td>\n",
       "      <td>45</td>\n",
       "      <td>2.364687</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term  reviews_containing_term  percentage  rank\n",
       "1651  customer service                      368   19.337888     1\n",
       "6994            time i                       73    3.836048     2\n",
       "4553         new phone                       68    3.573305     3\n",
       "4428  network coverage                       48    2.522333     4\n",
       "3884    loyal customer                       45    2.364687     5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get count of documents each word or phrase appears in\n",
    "# As well as percentage, and rank\n",
    "\n",
    "def doc_count(df, column):\n",
    "    # Produce a 2 column df with the document ID and the column to be measured\n",
    "    temp_df = pd.DataFrame(columns=['review_id', 'term'])\n",
    "    num_reviews = df.review_id.nunique()\n",
    "    for i in range(len(df)):\n",
    "        review_id = df['review_id'].iloc[i]\n",
    "        for item in df[column].iloc[i]:\n",
    "            term = item[0]\n",
    "            temp_df = temp_df.append(pd.DataFrame([[review_id, term]], columns = [\"review_id\", \"term\"]))\n",
    "            \n",
    "    results = temp_df.groupby(by='term', as_index=False).agg({'review_id': pd.Series.nunique})\n",
    "    results['percentage'] = results['review_id']/num_reviews * 100\n",
    "    results = results.sort_values(by='percentage',ascending=False)\n",
    "    # add a column for rank\n",
    "    results['rank'] = 0\n",
    "    r = 1\n",
    "    for i in range(len(results)):\n",
    "        results['rank'].iloc[i] = r\n",
    "        r += 1\n",
    "    \n",
    "    results = results.rename(columns={\"review_id\": \"reviews_containing_term\"})\n",
    "    return results\n",
    "    \n",
    "    \n",
    "doc_count(preprocessed_vodafone_reviews, 'noun_phrases').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company database leak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vodafone account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>factor authentication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>friday afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two factor authentication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        term\n",
       "0      company database leak\n",
       "1           vodafone account\n",
       "2      factor authentication\n",
       "3           friday afternoon\n",
       "4  two factor authentication"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a dataframe containing all unique terms for\n",
    "# a list encoded feature column\n",
    "def get_unique_terms(df, column):\n",
    "    \n",
    "    temp_df = pd.DataFrame(columns=['term'])\n",
    "    for i in range(len(df)):\n",
    "        for item in df[column].iloc[i]:\n",
    "            term = item[0]\n",
    "            temp_df = temp_df.append(pd.DataFrame([[term]], columns = [\"term\"]))\n",
    "            \n",
    "    return pd.DataFrame(temp_df.term.unique(), columns=['term'])\n",
    "\n",
    "get_unique_terms(preprocessed_vodafone_reviews, 'noun_phrases').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>perc_detractor</th>\n",
       "      <th>perc_passive</th>\n",
       "      <th>perc_promoter</th>\n",
       "      <th>total_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>excellent customer service</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.844156</td>\n",
       "      <td>5.844156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>excellent service</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.844156</td>\n",
       "      <td>5.844156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>new phone</td>\n",
       "      <td>3.179364</td>\n",
       "      <td>4.878049</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>3.963493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>great customer service</td>\n",
       "      <td>0.119976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.896104</td>\n",
       "      <td>3.776128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>great service</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>3.658537</td>\n",
       "      <td>3.896104</td>\n",
       "      <td>3.716140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            term  perc_detractor  perc_passive  perc_promoter  \\\n",
       "102   excellent customer service        0.000000      0.000000       5.844156   \n",
       "371            excellent service        0.000000      0.000000       5.844156   \n",
       "93                     new phone        3.179364      4.878049       7.142857   \n",
       "3393      great customer service        0.119976      0.000000       3.896104   \n",
       "941                great service        0.179964      3.658537       3.896104   \n",
       "\n",
       "      total_change  \n",
       "102       5.844156  \n",
       "371       5.844156  \n",
       "93        3.963493  \n",
       "3393      3.776128  \n",
       "941       3.716140  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For revoews containing each term, return the percentage\n",
    "# of the reviews that are Detractors, Promoters, and  passive customers\n",
    "# as well as the difference in count between\n",
    "# detractors and promoters\n",
    "\n",
    "def track_rank_changes(df, column):\n",
    "    #results = pd.DataFrame(columns=['term', 'perc_detractor', 'perc_passive', 'perc_promoter', 'total_change'])\n",
    "    all_unique_terms = get_unique_terms(df, column)\n",
    "    #print(all_unique_terms)\n",
    "    all_unique_terms['perc_detractor'] = 0\n",
    "    all_unique_terms['perc_passive'] = 0\n",
    "    all_unique_terms['perc_promoter'] = 0\n",
    "    all_unique_terms['total_change'] = 0    \n",
    "    \n",
    "    \n",
    "    detractors = doc_count(df[df['score'] <=3], column)\n",
    "    passive = doc_count(df[df['score'] ==4], column)\n",
    "    promotors = doc_count(df[df['score'] ==5], column)\n",
    "    \n",
    "    for i in range(len(all_unique_terms)):\n",
    "        if all_unique_terms['term'].iloc[i] in detractors['term'].tolist():\n",
    "            perc_detractor = detractors[detractors['term'] == all_unique_terms['term'].iloc[i]].percentage.iloc[0]\n",
    "        else:\n",
    "            perc_detractor = 0\n",
    "            \n",
    "        if all_unique_terms['term'].iloc[i] in passive['term'].tolist():\n",
    "            perc_passive = passive[passive['term'] == all_unique_terms['term'].iloc[i]].percentage.iloc[0]\n",
    "        else:\n",
    "            perc_passive = 0\n",
    "        \n",
    "        if all_unique_terms['term'].iloc[i] in promotors['term'].tolist():\n",
    "            perc_promoter = promotors[promotors['term'] == all_unique_terms['term'].iloc[i]].percentage.iloc[0]\n",
    "        else:\n",
    "            perc_promoter = 0\n",
    "            \n",
    "        total_change = perc_promoter - perc_detractor\n",
    "        \n",
    "        all_unique_terms['perc_detractor'].iloc[i] = perc_detractor\n",
    "        all_unique_terms['perc_passive'].iloc[i] = perc_passive\n",
    "        all_unique_terms['perc_promoter'].iloc[i] = perc_promoter\n",
    "        all_unique_terms['total_change'].iloc[i] = total_change        \n",
    "\n",
    "    return all_unique_terms.sort_values(by='total_change',ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "track_rank_changes(preprocessed_vodafone_reviews, 'noun_phrases').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
